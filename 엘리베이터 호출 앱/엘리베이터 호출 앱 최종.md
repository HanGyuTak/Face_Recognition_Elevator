#  엘리베이터 호출 앱
# 1.1. 앱 제작
<img src="https://user-images.githubusercontent.com/81175672/185388684-212cac5d-cf88-47b1-bbbb-c2eab00ca364.JPG"  width="1000" height="600"/>                        

***           
다음과 같이 뷰어와 컴포넌트를 구성해준다.           
- 수평배치1
  - 목록_블루투스(목록선택버튼)
  - 버튼_연결끊기(버튼)
  - 버튼_카메라_전환(버튼)
  
- 웹뷰어1          

- 수평배치2
  - 버튼_인식하기(버튼)
  - 버튼_도착_층_정하기(버튼)

- 수평배치3
  - 텍스트박스1
  - 버튼_전송하기 

- 레이블_표시
- PersonalImageClassifier1
- 블루투스클라이언트1
- 알림1
- 음성인식1

***
**목록_블루투스** - 너비: 부모 요소에 맞추기, 텍스트: 연결하기                     
**버튼_연결끊기** - 너비: 부모 요소에 맞추기, 텍스트: 연결끊기           
**버튼_카메라_전환** - 너비: 부모 요소에 맞추기, 텍스트: 카메라 전환
**버튼_인식하기** - 너비: 부모 요소에 맞추기, 텍스트: 인식하기                     
**버튼_도착_층_정하기** - 너비: 부모 요소에 맞추기, 텍스트: 도착 층 정하기      
**텍스트박스1** - 너비: 부모 요소에 맞추기, 텍스트: (공백)
**버튼_전송하기** - 텍스트: 전송하기 
**레이블_표시** - 너비: 부모 요소에 맞추기, 텍스트: ...          
**PersonalImageClassifier1** - Model: ([추가 기능 API 다운 링크](https://mit-cml.github.io/extensions/)에서 다운받은 파일), WebViewer: 웹뷰어1

***

# 1.2. 앱 코딩
블루투스 통신 클라이언트, 카메라 웹 뷰어, 음성인식 등을 활용하여 앱의 주요 기능들을 구현했습니다.                                                                       
인식한 데이터에 따라 앱에서는 블루투스 신호 송신하고, 아두이노에서는 수신된 데이터에 따라 작동을 합니다.             
<img src="https://user-images.githubusercontent.com/81175672/185392710-b4b7b4d0-0fab-4b40-80da-1b63dc4ff177.JPG"  width="900" height="600"/>          

**<출력>, <연결됨>, <연결끊기> 함수** 를 만들어 상태에 맞는 텍스트가 나오도록 지정함        

<img src="https://user-images.githubusercontent.com/81175672/182079924-eabbc2ff-2b23-4177-955a-7be5973c7bdf.JPG"  width="900" height="600"/>               

**목록_블루투스** 가 선택되기 전, 블루투스클라이언트로부터 주소와 이름을 가져오는 과정과 선택된 후, 목록 선택한 항목으로 블루투스 연결하는 것을 지정한다.           
**버튼_연결끊기** 를 클릭했을 때 블루투스 연결이 끊어지도록 지정한다.       

<img src="https://user-images.githubusercontent.com/81175672/182079960-c15cb711-e6b1-4f76-8f01-061d931951bd.JPG"  width="900" height="600"/>             

감지된 사람이 누구인지 저장할 전역변수 **사람** 을 Nobody로 초기화         
Screen1이 초기화 되었을 때는 버튼을 비활성화 시키고 Classifier가 준비되었을 때 활성화시키도록  함.     
**버튼_인식하기** 를 클릭했을 때 Video로 이미지 분석을 실행하도록 지정              


<img src="https://user-images.githubusercontent.com/81175672/182080004-7a63e7d5-c65d-4f3e-abb8-10fbffc9f329.JPG"  width="900" height="600"/>             

이미지 분석 완료 후, 인식되는 사람에 따른 텍스트 값을 아두이노로 전송하도록 함.   

<img src="https://user-images.githubusercontent.com/81175672/182549960-b0252eaf-db10-4412-a193-6f12938c9795.JPG"  width="600" height="300"/>                 

아두이노에 명령을 내리는 텍스트를 전달하는 **전송하기 함수** 를 만든다.             
<img src="https://user-images.githubusercontent.com/81175672/182549602-b58898cc-1142-4e2e-ac12-9e096de6a135.JPG"  width="800" height="500"/>                     

**버튼 층 정하기** 버튼을 누르면 음성 인식으로 텍스트를 가져오는 함수, 가져오기 전에 레이블을 리셋하는 함수를 지정한다.                
<img src="https://user-images.githubusercontent.com/81175672/182552905-9b0c87fb-a21a-4305-8375-ee7541afb565.JPG"  width="600" height="900"/>                   

얼굴 인식 호출 함수 뒤에 **인식하기 버튼** 비활성화, **버튼 층 정하기** 활성화 명령을 추가한다.     
얼굴인식과 음성인식 순서로 인한 오류를 막기 위해 추가해주어야 한다.        

<img src="https://user-images.githubusercontent.com/81175672/182549606-72c499a2-ce4f-4c45-bc2a-0d932b846073.JPG"  width="500" height="900"/>           

우선 도착층 호출 성공 여부를 저장한 **호출성공여부** 변수를 선언하고 0으로 초기화한다.    
그 다음 호출한 각 층에 따라 다음과 같이 작동하도록 코드를 작성한다.      
***
- 호출한 층에 따라 아두이노가 수행할 명령 번호를 전송
- 도착지를 레이블에 출력
- **호출성공여부** 를 1로 바꾸기
***
호출이 **실패**한 경우에 대해서는 다음과 같이 코드를 작성한다.
***
- _잘못된 선택지입니다. 다시 진행해주세요_ 출력
- **호출성공여부** 를 0으로 바꾸기
***

<img src="https://user-images.githubusercontent.com/81175672/184079870-ec3239b7-5e08-4f56-84cb-706216fe9c43.JPG"  width="500" height="900"/>             

키패드 인식부분도 음성인식부분과 코드가 같으며 **지역 변수 VOICE** 와 **음성인식1 - 결과** 부분을 
**지역 변수 keypad**, **텍스트박스1 - 텍스트** 로 바꾸면 된다.           

